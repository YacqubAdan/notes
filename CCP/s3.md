# Amazon S3

Subject Tags: AWS
Created time: October 8, 2024 1:46 PM
Last edited time: October 9, 2024 12:01 PM

## Amazon S3 - Security

**User**-**Based**: ****

- **IAM Policies** - ًWhich API calls should be allowed for a specific user from IAM

**Resource**-**Based**: 

- **Bucket Policies** - bucket wide rules from the S3 console - allows cross accounts.
- **Object Access Control List (ACL)** - finer grain (can be disabled)

***An IAM principal can access an S3 Bucket if:**

- The user IAM permissions **allow** it OR the resource policy **allows** it.
- **AND** there’s no explicit **DENY**

**Encryption:** encrypt objects in Amazon S3 using encryption keys

### Bucket Policies

**JSON based policies**

- Resources: buckets and objects
- Effect: Allow / Deny
- Actions: Set of API to Allow or Deny
- Principle: The account or user to apply the policy to

```json
{
		"version": "2012-10-17",
		"statement": [
				{
						"Sid": "Public Read",
						"Effect": "Allow",
						"Principle": "*",
						"Action": [
								"s3:GetObject"
						],
						"Resource": [
								"arn:aws:s3:::examplebucket/*"
						] 
		
				}
		]
}
```

## S3 - Static Website Hosting

**S3 can host static websites and have them accessible on the Internet**

**The website URL will be (depending on the region)**

- http:*//bucket-name.s3-website-AWS-region.amazonaws.com*
- *https://bucket-name.s3-website-AWS-region.amazonaws.com*

If you get a **403 Forbidden error,** make sure the bucket policy allows **public reads!**

### S3 Versioning

You can version your files in Amazon S3

It is enabled at the **bucket level**

Same key overwrite will change the version: 1,2,3

It is best practise to version your buckets:

- Protect against unintended deletes (ability to restore)
- Easily rollback to a previous version

*Any file that is not versioned prior to enabling will have a version **“null”**

### S3 Replication (CRR SRR)

Cross Region Replication

Same Region Replication

**Must enable version aging in source and destination buckets**

- Buckets can be in different AWS accounts
- Copying is asynchronous
- Must give proper IAM permissions to S3

Use Cases:

- CRR - Compliance, lower latency access, replication across accounts
- SRR - log aggregation, live replication between production and test accounts

STEPS: 

- Create a two buckets and enable versioning on each
- Go to management tab and click on replication rule config
- Create a rule name and for rule scope apply to all objects in bucket
- Choose a destination bucket

### S3 Storage Classes

- Standard - General Purpose - 99.99% availability, frequently accessed data, low latency, sustain 2 concurrent facility failures
    
    Use cases: Big Data analytics, mobile and gaming applications, content distribution 
    
- Standard-Infrequent Access(IA) - 99.9% availability
    
    Use cases: Disaster recovery, backups
    
- One Zone-Infrequent Access - High durability within single AZ; Data is **lost** when AZ is destroyed, 99.5% availability.

Glacier Storage Classes

Low-cost object storage meant for archiving/backup

Pricing: price for storage + object retrieval costs 

- Glacier Instant Retrieval: Milliseconds retrieval, great for data accessed once a quarter. Minimum storage duration **90** days
- Glacier Flexible Retrieval: Expedited  (1 to 5 mins), standard (3 to 5 hours), bulk (5 to 12 hours). Minimum storage duration **90** days
- Glacier Deep Archive: **Long term storage:** standard (12 hours), bulk (48 hours). Minimum duration **180** days.
- Intelligent Tiering: moves object between access tiers automatically. Small monitoring fee and auto-tiering fee. No retrieval charges
    - Frequent access tier: default
    - Infrequent access tier (automatic): objects not accessed for 30 days
    - Archive instant access (automatic): objects not accessed for 90 days
    - Archive access tier (optional): configurable from 90 days to 700+
    - Deep Archive Access tier (optional): config. From 180 days to 700+

Can move between classes manually  using S3 lifecycle configurations 

### Encryption (**one question**)

Server side (default)

- user uploads object on object on s3 and it will be encrypted by AWS
- Server is doing the encryption

Client side

- when user encrypts the file before uploading it and then put it into the bucket

### IAM Access Analyser for S3

- Ensures that only intended people have access to your s3 bucket
- Example: A public accessible bucket which is shared with other AWS accounts
- Evaluates s3 bucket policies, s3 ACLs, s3 Access Point Policies
- Powered by IAM Access Analyser

### Snow Family

Highly Secure, portable devices to collect and process data at the edge, and migrate data into and out of AWS. 

- Snowcone
    - Storage Capacity → 8 TB HDD - 14 TB SSD
    - Migration Size → up to **terabytes**
- Snowball Edge
    - Storage Capacity → 80 TB - 210 TB
    - Migration Size → up to **petabytes**
    

**Data Migrations**

**Challenges:**

- Limited connectivity
- Limited bandwidth
- High network costs

If it takes you **more than a week** to transfer data over the network, use **snowball devices** since its an offline data transfer that works by ordering a snowcone or ball device and load the data onto it and ship back to AWS who do it offline.

**Edge Computing**

- Process data while its being created on an edge location
    - A truck on the road, a ship on the sea, a mining station underground
- These locations may have limited internet and no access to computing power
- We setup a Snowball Edge / Snowcone device to do edge computing.
    - Snowcone: 2 CPUs, 4 GB of memory, wired or wireless access
    - Snowball Edge Compute Optimised (dedicated for that use case) & Storage optimised
    - Run EC2 Instances or Lambda functions at the edge

Use Cases: preprocess data, machine learning, transcoding media 

### Snowball Edge Pricing

- You pay for device usage and data transfer **out** of AWS
- Data transfer **IN is free**
- On-Demand
    - Includes a one-time service fee per job, which includes:
        - 10 days of usage for snowball edge store optimised 80TB
        - 15 days of usage for snowball edge storage optimised 210TB
    - Shipping days are **NOT** counted towards the included 10, 15 days
    - Pay per day for any additional days
- Committed Upfront
    - pay in advance for monthly, 1-year, and 3-year usage (edge computing)
    - Up to 62% discounted pricing

### Hybrid Cloud for Storage

- AWS pushing for “hybrid cloud” where half is on-premise and half is on the cloud
- Due to:
    - Long cloud migrations
    - Security requirements
    - Compliance requirements
    - IT strategy
- S3 is a proprietary storage technology ( unlike EFS, NFS ), so how do you expose the s3 data on-premise?
- AWS Storage Gateway

**AWS Storage Cloud Native Options**

- Block
    - Amazon EBS
    - EC2 Instance Store
- File
    - Amazon EFS
- Object
    - Amazon S3
    - Glacier

**AWS Storage Gateway**

- Bridge between on premise data and cloud data in S3
- Hybrid storage service to allow on premise to seamlessly use AWS Cloud
- Use cases: disaster recovery, backup & restore, tiered storage
- Types of storage gateway
    - File gateway
    - Volume Gateway
    - Tape Gateway

S3 SUMMARY

- Buckets vs Objects → global unique name, tied to a region and objects live within these buckets
- S3 Security → IAM Policy, S3 Bucket Policies, S3 Encryption
- S3 Websites → host static website on Amazon.
- S3 Versioning → multiple versions for files, prevents accidental deletes, roll backs can be done
- S3 Replication → same region replication, cross replication
- S3 Storage Classes → Standard, IA, OZ-IA, Intelligent, Glacier (Instant, Flexible, Deep)
- Snow Family → Physical devices to import data into amazon s3, edge computing. Snowcone snowball edge
- Ops hub → desktop app to manage snowball devices
- Storage Gateway → a way to bridge on premise and on cloud storage onto s3